{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "# add root folder to path\n",
    "folder = \"../../\"\n",
    "sys.path.append(folder)\n",
    "from src.utils import load_data\n",
    "from src.utils import plot_metrics_grid\n",
    "from src.utils import load_baseline_rec_result\n",
    "from src.metrics import evaluate_recommender_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users,ratings,movies = load_data('../../data/ml-1m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44870/3774346294.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['year'].fillna(data['year'].median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416292</th>\n",
       "      <td>2507</td>\n",
       "      <td>3035</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683230</th>\n",
       "      <td>4087</td>\n",
       "      <td>2840</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>19</td>\n",
       "      <td>457</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688533</th>\n",
       "      <td>4118</td>\n",
       "      <td>2804</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472584</th>\n",
       "      <td>2907</td>\n",
       "      <td>805</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating  gender  age  occupation    year  Action  \\\n",
       "416292     2507      3035       2    True   25           4  1955.0   False   \n",
       "683230     4087      2840       4    True    1           4  1999.0   False   \n",
       "2434         19       457       3    True    1          10  1993.0    True   \n",
       "688533     4118      2804       4    True   25           3  1983.0   False   \n",
       "472584     2907       805       4   False   35           5  1996.0   False   \n",
       "\n",
       "        Adventure  Animation  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "416292      False      False  ...    False      False   False    False   \n",
       "683230      False      False  ...    False      False   False    False   \n",
       "2434        False      False  ...    False      False   False    False   \n",
       "688533      False      False  ...    False      False   False    False   \n",
       "472584      False      False  ...    False      False   False    False   \n",
       "\n",
       "        Mystery  Romance  Sci-Fi  Thriller    War  Western  \n",
       "416292    False    False   False     False   True    False  \n",
       "683230    False    False   False      True  False    False  \n",
       "2434      False    False   False      True  False    False  \n",
       "688533    False    False   False     False  False    False  \n",
       "472584    False    False   False     False  False    False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Merge the datasets\n",
    "data = ratings.merge(users, on='user_id').merge(movies, on='movie_id')\n",
    "\n",
    "# Extract year from title\n",
    "data['year'] = data['title'].str.extract(r'\\((\\d{4})\\)').astype(float)\n",
    "\n",
    "# Split genres into separate columns\n",
    "data['genres'] = data['genres'].str.split('|')\n",
    "\n",
    "# Create a DataFrame for each unique genre and merge them into the main DataFrame\n",
    "genres_expanded = data['genres'].explode().unique()\n",
    "genre_columns = pd.get_dummies(data['genres'].explode()).groupby(level=0).max()\n",
    "\n",
    "# Join the new genre columns to the main DataFrame\n",
    "data = data.join(genre_columns)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['title', 'genres', 'zip'])\n",
    "\n",
    "# Fill missing year values with the median year\n",
    "data['year'].fillna(data['year'].median(), inplace=True)\n",
    "\n",
    "data['gender'] = data['gender'].apply(lambda x: x == 'M')\n",
    "data.drop(columns=['timestamp'], inplace=True)\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the resulting DataFrames to check the changes\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_features_names = ['year', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
    "                'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
    "                'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_listwise_data(data, num_documents=25, k=1):\n",
    "    grouped_data = data.groupby('user_id')\n",
    "    listwise_data = []\n",
    "\n",
    "    for user_id, sub_df in grouped_data:\n",
    "        # Extract user features\n",
    "        user_features = sub_df[['gender', 'age', 'occupation']].iloc[0].values\n",
    "\n",
    "        for _ in range(k):\n",
    "            # Sample documents for the user\n",
    "            num_samples = min(num_documents, sub_df.shape[0])\n",
    "            movie_samples = sub_df.sample(n=num_samples)\n",
    "\n",
    "            # Extract movie features and relevance scores\n",
    "            movie_features = movie_samples[movie_features_names].values\n",
    "            relevance_scores = movie_samples['rating'].values\n",
    "\n",
    "            # Pad movie features and relevance scores if fewer than num_documents\n",
    "            if num_samples < num_documents:\n",
    "                padding_size = num_documents - num_samples\n",
    "                \n",
    "                # Pad movie features with -1 and relevance scores with 0\n",
    "                padded_movie_features = np.vstack([\n",
    "                    movie_features,\n",
    "                    np.full((padding_size, movie_features.shape[1]), -1)\n",
    "                ])\n",
    "                padded_relevance_scores = np.concatenate([\n",
    "                    relevance_scores,\n",
    "                    np.full(padding_size, 0)\n",
    "                ])\n",
    "            else:\n",
    "                padded_movie_features = movie_features\n",
    "                padded_relevance_scores = relevance_scores\n",
    "            \n",
    "            listwise_data.append((user_features, padded_movie_features, padded_relevance_scores))\n",
    "    \n",
    "    # Shuffle listwise_data to mix padded data positions\n",
    "    np.random.shuffle(listwise_data)\n",
    "\n",
    "    return listwise_data\n",
    "\n",
    "# Example usage:\n",
    "train_listwise = generate_listwise_data(train_data, num_documents=25, k=15)\n",
    "test_listwise = generate_listwise_data(test_data, num_documents=25, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class ListwiseDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list of tuples): Each tuple contains (user_features, movie_features, relevance_scores)\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_features, movie_features, relevance_scores = self.data_list[idx]\n",
    "        return {\n",
    "            'user_features': torch.tensor(user_features.astype(np.float32), dtype=torch.float),\n",
    "            'movie_features': torch.tensor(movie_features.astype(np.float32), dtype=torch.float),\n",
    "            'relevance_scores': torch.tensor(relevance_scores.astype(np.float32), dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "train_dataset = ListwiseDataset(train_listwise)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = ListwiseDataset(test_listwise)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ListwiseRankingModel(nn.Module):\n",
    "    def __init__(self, user_feature_dim, movie_feature_dim, hidden_dim=64):\n",
    "        super(ListwiseRankingModel, self).__init__()\n",
    "        self.user_feature_layer = nn.Linear(user_feature_dim, hidden_dim)\n",
    "        self.movie_feature_layer = nn.Linear(movie_feature_dim, hidden_dim)\n",
    "        self.merging_layer = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user_features, movie_features):\n",
    "        # Process user features\n",
    "        user_hidden = F.relu(self.user_feature_layer(user_features))\n",
    "        \n",
    "        # Process movie features\n",
    "        movie_hidden = F.relu(self.movie_feature_layer(movie_features))\n",
    "        \n",
    "        # Merge user and movie features\n",
    "        merged_features = torch.cat((user_hidden.unsqueeze(1).repeat(1, movie_features.size(1), 1), movie_hidden), dim=2)\n",
    "        merged_hidden = F.relu(self.merging_layer(merged_features))\n",
    "        \n",
    "        # Compute scores for each movie\n",
    "        scores = self.output_layer(merged_hidden)\n",
    "        return scores.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0826, 0.1650, 0.1250, 0.1298, 0.1530, 0.1319, 0.0607, 0.1825, 0.1290,\n",
      "        0.1463, 0.0593, 0.1144, 0.1258, 0.0847, 0.2279, 0.0480, 0.1915, 0.0648,\n",
      "        0.1219, 0.1895, 0.0604, 0.0485, 0.1525, 0.1831, 0.1956],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "user_feature_dim = len(['gender', 'age', 'occupation'])\n",
    "movie_feature_dim = len(movie_features_names)\n",
    "\n",
    "model = ListwiseRankingModel(user_feature_dim, movie_feature_dim)\n",
    "# Example input\n",
    "user_features = torch.randn(1, user_feature_dim)  # Example user features\n",
    "movie_features = torch.randn(1, 25, movie_feature_dim)  # Example movie features for 25 movies\n",
    "\n",
    "scores = model(user_features, movie_features)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training NDCG: 0.9225, MAP: 0.0000\n",
      "Epoch 1/2, Loss: 1.1917\n",
      "Epoch 1/2, Training NDCG: 0.9196, MAP: 0.0000\n",
      "Epoch 1/2, Validation NDCG: 0.9225, MAP: 0.0000\n",
      "Epoch 2/2, Loss: 1.1918\n",
      "Epoch 2/2, Training NDCG: 0.9196, MAP: 0.0000\n",
      "Epoch 2/2, Validation NDCG: 0.9225, MAP: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def mse_loss(pred_scores, true_scores):\n",
    "    return F.mse_loss(pred_scores, true_scores)\n",
    "\n",
    "# Loss function\n",
    "def listnet_loss(pred_scores, true_scores):\n",
    "    true_probs = F.softmax(true_scores, dim=1)\n",
    "    pred_probs = F.softmax(pred_scores, dim=1)\n",
    "    return -torch.mean(torch.sum(true_probs * torch.log(pred_probs + 1e-8), dim=1))\n",
    "\n",
    "# Metrics computation\n",
    "def compute_metrics(pred_scores, true_scores):\n",
    "    ndcg = ndcg_score(true_scores, pred_scores)\n",
    "    avg_precision = 0# average_precision_score(true_scores, pred_scores)\n",
    "    return ndcg, avg_precision\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, num_epochs=10, learning_rate=0.001):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Evaluate on validation set before training\n",
    "    model.eval()\n",
    "    all_pred_scores = []\n",
    "    all_true_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            user_features = batch['user_features'].to(device)\n",
    "            movie_features = batch['movie_features'].to(device)\n",
    "            relevance_scores = batch['relevance_scores'].to(device)\n",
    "            pred_scores = model(user_features, movie_features)\n",
    "            all_pred_scores.append(pred_scores.cpu().numpy())\n",
    "            all_true_scores.append(relevance_scores.cpu().numpy())\n",
    "    \n",
    "    pred_scores = np.concatenate(all_pred_scores)\n",
    "    true_scores = np.concatenate(all_true_scores)\n",
    "    \n",
    "    ndcg, avg_precision = compute_metrics(pred_scores, true_scores)\n",
    "    print(f'Before training NDCG: {ndcg:.4f}, MAP: {avg_precision:.4f}')\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_dataloader:\n",
    "            user_features = batch['user_features'].to(device)\n",
    "            movie_features = batch['movie_features'].to(device)\n",
    "            relevance_scores = batch['relevance_scores'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_scores = model(user_features, movie_features)\n",
    "            loss = mse_loss(pred_scores, relevance_scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        # Evaluate on training set\n",
    "        model.eval()\n",
    "        all_pred_scores = []\n",
    "        all_true_scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch in train_dataloader:\n",
    "                user_features = batch['user_features'].to(device)\n",
    "                movie_features = batch['movie_features'].to(device)\n",
    "                relevance_scores = batch['relevance_scores'].to(device)\n",
    "                \n",
    "                pred_scores = model(user_features, movie_features)\n",
    "                all_pred_scores.append(pred_scores.cpu().numpy())\n",
    "                all_true_scores.append(relevance_scores.cpu().numpy())\n",
    "        \n",
    "        pred_scores = np.concatenate(all_pred_scores)\n",
    "        true_scores = np.concatenate(all_true_scores)\n",
    "        \n",
    "        train_ndcg, train_avg_precision = compute_metrics(pred_scores, true_scores)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Training NDCG: {train_ndcg:.4f}, MAP: {train_avg_precision:.4f}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        all_pred_scores = []\n",
    "        all_true_scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                user_features = batch['user_features'].to(device)\n",
    "                movie_features = batch['movie_features'].to(device)\n",
    "                relevance_scores = batch['relevance_scores'].to(device)\n",
    "                \n",
    "                pred_scores = model(user_features, movie_features)\n",
    "                all_pred_scores.append(pred_scores.cpu().numpy())\n",
    "                all_true_scores.append(relevance_scores.cpu().numpy())\n",
    "        \n",
    "        pred_scores = np.concatenate(all_pred_scores)\n",
    "        true_scores = np.concatenate(all_true_scores)\n",
    "        \n",
    "        val_ndcg, val_avg_precision = compute_metrics(pred_scores, true_scores)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation NDCG: {val_ndcg:.4f}, MAP: {val_avg_precision:.4f}')\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "train_and_evaluate(model, train_dataloader, test_dataloader, num_epochs=2, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_id_unique = test_data['user_id'].unique()\n",
    "movie_id_unique = test_data['movie_id'].unique()\n",
    "\n",
    "#sample for each user 25 random movies that he has in test set\n",
    "recommendations = {}\n",
    "for user_id in users_id_unique:\n",
    "    recommendations[int(user_id)] = np.random.choice(test_data['movie_id'], 5, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_recommendations(model, test_data, recommendations, device='cuda'):\n",
    "    model.eval()\n",
    "    ranked_recommendations = {}\n",
    "    \n",
    "    for user_id, movie_ids in recommendations.items():\n",
    "        \n",
    "        user_features = test_data[test_data['user_id'] == user_id][['gender', 'age', 'occupation']].iloc[0].values\n",
    "        movie_features = []\n",
    "        for movie_id in movie_ids:\n",
    "            movie_features.append(test_data[test_data['movie_id'] == movie_id][movie_features_names].iloc[0].values)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        user_features = np.array(user_features)\n",
    "        movie_features = np.array(movie_features)\n",
    "\n",
    "        # Check the shape of movie_features\n",
    "\n",
    "        # We need to add padding to the movie features if there are less than 25 movies\n",
    "        num_movies = len(movie_ids)\n",
    "        num_features_per_movie = len(movie_features_names)\n",
    "\n",
    "        if num_movies < 25:\n",
    "            padding_size = 25 - num_movies\n",
    "            # Create a padding array of shape (padding_size, num_features_per_movie) filled with -1\n",
    "            padding_array = -1 * np.ones((padding_size, num_features_per_movie))\n",
    "            # Append the padding array to movie_features\n",
    "            movie_features = np.vstack((movie_features, padding_array))\n",
    "        \n",
    "        \n",
    "        # Convert to tensors\n",
    "        user_features_tensor = torch.tensor(user_features.astype(np.float32), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        movie_features_tensor = torch.tensor(movie_features.astype(np.float32), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        pred_scores = model(user_features_tensor, movie_features_tensor)\n",
    "        \n",
    "        # Sort movie_ids based on predicted scores\n",
    "        # pick only not padded movie ids\n",
    "        pred_scores = pred_scores[:num_movies]\n",
    "        sorted_indices = torch.argsort(pred_scores, descending=True).cpu().numpy()\n",
    "        ranked_recommendations[user_id] = [movie_ids[i] for i in sorted_indices]\n",
    "    \n",
    "    return ranked_recommendations\n",
    "\n",
    "\n",
    "ranked_recommendations = rank_recommendations(model, test_data, recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amount_of_movies = test_data['movie_id'].nunique()\n",
    "random_res = evaluate_recommender_system(recommendations, test_data, total_amount_of_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_random_res = evaluate_recommender_system(ranked_recommendations, test_data, total_amount_of_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@K': np.float64(0.02805564756541902),\n",
       " 'Recall@K': np.float64(0.004659922027470331),\n",
       " 'NDCG@K': np.float64(0.5966269300717518),\n",
       " 'MAP@K': np.float64(0.4557720057720058),\n",
       " 'MRR': np.float64(0.058545876117919844),\n",
       " 'Hit Rate@K': np.float64(0.1275256707519046),\n",
       " 'Coverage@K': 0.8246225319396051}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@K': np.float64(0.02805564756541902),\n",
       " 'Recall@K': np.float64(0.004659922027470331),\n",
       " 'NDCG@K': np.float64(0.5952947606684268),\n",
       " 'MAP@K': np.float64(0.45756854256854257),\n",
       " 'MRR': np.float64(0.059299436899635634),\n",
       " 'Hit Rate@K': np.float64(0.1275256707519046),\n",
       " 'Coverage@K': 0.8246225319396051}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_random_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../../artifacts/listwise_ranking_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We can see slight changes in ranking metrics, however they are not really that positive, we assume that this is because ranking can not solve the issue of recommending model meaning that in this specific case we randomly select recommendations and if there no good recommendations in provided by recommender model the ranking just does not make much sense. Another assumption might be that the model is overfitted even though it has high NDCG on eval data, there might be some issues with preparing data for model training which might explain very little impact on ranking afterwards.\n",
    "\n",
    "We will know in more details whether ranking helps us when we will combine ranking with providing better recommendations for ranking model in second task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
