{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee5056dad5d316a",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MOVIES_PATH, RATINGS_PATH\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[0;32m---> 12\u001b[0m movies, ratings \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/ml-1m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m cutoff_date \u001b[38;5;241m=\u001b[39m ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.8\u001b[39m)  \u001b[38;5;66;03m# 80% of the data for training, 20% for testing\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import sys\n",
    "# add root folder to path\n",
    "folder = \"../../\"\n",
    "sys.path.append(folder)\n",
    "import src.utils as utils\n",
    "from src.config import MOVIES_PATH, RATINGS_PATH\n",
    "from src.utils import load_data\n",
    "users,ratings,movies = load_data('../../data/ml-1m')\n",
    "\n",
    "ratings['Timestamp'] = pd.to_datetime(ratings['Timestamp'])\n",
    "\n",
    "cutoff_date = ratings['Timestamp'].quantile(0.8)  # 80% of the data for training, 20% for testing\n",
    "train_ratings = ratings[ratings['Timestamp'] <= cutoff_date]\n",
    "test_ratings = ratings[ratings['Timestamp'] > cutoff_date]\n",
    "\n",
    "train_movie_ids = train_ratings['MovieID'].unique()\n",
    "test_movie_ids = test_ratings['MovieID'].unique()\n",
    "\n",
    "train_movies = movies[movies['MovieID'].isin(train_movie_ids)]\n",
    "test_movies = movies[movies['MovieID'].isin(test_movie_ids)]\n",
    "\n",
    "# Ensure the indices are reset to avoid out of bound errors\n",
    "train_movies = train_movies.reset_index(drop=True)\n",
    "test_movies = test_movies.reset_index(drop=True)\n",
    "\n",
    "title_to_index = pd.Series(train_movies.index, index=train_movies['Title']).drop_duplicates()\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "train_movies['Genres'] = train_movies['Genres'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(train_movies['Genres'])\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    if title not in title_to_index:\n",
    "        return []\n",
    "    idx = title_to_index[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    return train_movies['Title'].iloc[movie_indices]\n",
    "\n",
    "\n",
    "print(get_recommendations('Toy Story (1995)'))\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    relevant_movies = 0\n",
    "    recommended_relevant_movies = 0\n",
    "    total_recommendations = 0\n",
    "\n",
    "    for title in test_movies['Title']:\n",
    "        recommendations = get_recommendations(title)\n",
    "        test_user_ratings = test_ratings[test_ratings['MovieID'].isin(test_movies[test_movies['Title'].isin(recommendations)]['MovieID'])]\n",
    "\n",
    "        relevant_movies += len(test_user_ratings)\n",
    "        recommended_relevant_movies += sum(test_user_ratings['Rating'] >= 4)\n",
    "        total_recommendations += len(recommendations)\n",
    "\n",
    "    precision = recommended_relevant_movies / total_recommendations if total_recommendations > 0 else 0\n",
    "    recall = recommended_relevant_movies / relevant_movies if relevant_movies > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "precision, recall, f1 = evaluate_model()\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04965a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
