{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "# add root folder to path\n",
    "folder = \"../../\"\n",
    "sys.path.append(folder)\n",
    "from src.utils import load_data\n",
    "from src.utils import plot_metrics_grid\n",
    "from src.utils import load_baseline_rec_result\n",
    "from src.metrics import evaluate_recommender_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users,ratings,movies = load_data('../../data/ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id gender  age  occupation    zip\n",
       "0           1      F    1          10  48067\n",
       "1           2      M   56          16  70072\n",
       "2           3      M   25          15  55117\n",
       "3           4      M   45           7  02460\n",
       "4           5      M   25          20  55455\n",
       "...       ...    ...  ...         ...    ...\n",
       "6035     6036      F   25          15  32603\n",
       "6036     6037      F   45           1  76006\n",
       "6037     6038      F   56           1  14706\n",
       "6038     6039      F   45           0  01060\n",
       "6039     6040      M   25           6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  rating  timestamp\n",
       "0              1      1193       5  978300760\n",
       "1              1       661       3  978302109\n",
       "2              1       914       3  978301968\n",
       "3              1      3408       4  978300275\n",
       "4              1      2355       5  978824291\n",
       "...          ...       ...     ...        ...\n",
       "1000204     6040      1091       1  956716541\n",
       "1000205     6040      1094       5  956704887\n",
       "1000206     6040       562       5  956704746\n",
       "1000207     6040      1096       4  956715648\n",
       "1000208     6040      1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                               title  \\\n",
       "0            1                    Toy Story (1995)   \n",
       "1            2                      Jumanji (1995)   \n",
       "2            3             Grumpier Old Men (1995)   \n",
       "3            4            Waiting to Exhale (1995)   \n",
       "4            5  Father of the Bride Part II (1995)   \n",
       "...        ...                                 ...   \n",
       "3878      3948             Meet the Parents (2000)   \n",
       "3879      3949          Requiem for a Dream (2000)   \n",
       "3880      3950                    Tigerland (2000)   \n",
       "3881      3951             Two Family House (2000)   \n",
       "3882      3952               Contender, The (2000)   \n",
       "\n",
       "                            genres  \n",
       "0      Animation|Children's|Comedy  \n",
       "1     Adventure|Children's|Fantasy  \n",
       "2                   Comedy|Romance  \n",
       "3                     Comedy|Drama  \n",
       "4                           Comedy  \n",
       "...                            ...  \n",
       "3878                        Comedy  \n",
       "3879                         Drama  \n",
       "3880                         Drama  \n",
       "3881                         Drama  \n",
       "3882                Drama|Thriller  \n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RecommenderV3(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_dim, n_user_features, n_movie_features):\n",
    "        super(RecommenderV3, self).__init__()\n",
    "        \n",
    "        # User embedding\n",
    "        self.user_embedding = nn.Embedding(n_users, n_dim)\n",
    "        self.user_dense = nn.Linear(n_dim + n_user_features, 64)\n",
    "        \n",
    "        # Movie embedding\n",
    "        self.movie_embedding = nn.Embedding(n_movies, n_dim)\n",
    "        self.movie_dense = nn.Linear(n_dim + n_movie_features, 64)\n",
    "        \n",
    "        # Final dense layers\n",
    "        self.final_dense1 = nn.Linear(128, 64)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.final_dense2 = nn.Linear(64, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.final_output = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, user, user_features, movie, movie_features):\n",
    "        # User branch\n",
    "        user_embedded = self.user_embedding(user).view(user.size(0), -1)\n",
    "        user_input = torch.cat([user_embedded, user_features], dim=1)\n",
    "        user_out = F.relu(self.user_dense(user_input))\n",
    "        \n",
    "        # Movie branch\n",
    "        movie_embedded = self.movie_embedding(movie).view(movie.size(0), -1)\n",
    "        movie_input = torch.cat([movie_embedded, movie_features], dim=1)\n",
    "        movie_out = F.relu(self.movie_dense(movie_input))\n",
    "        \n",
    "        # Concatenate user and movie branches\n",
    "        x = torch.cat([user_out, movie_out], dim=1)\n",
    "        x = F.relu(self.final_dense1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.final_dense2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.final_output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, MinMaxScaler\n",
    "\n",
    "# Process user data\n",
    "user_enc = LabelEncoder()\n",
    "users['user_id'] = user_enc.fit_transform(users['user_id']) + 1  # Start IDs from 1\n",
    "\n",
    "# Encode gender\n",
    "gender_enc = LabelEncoder()\n",
    "users['gender'] = gender_enc.fit_transform(users['gender'])\n",
    "\n",
    "# Normalize age\n",
    "age_scaler = MinMaxScaler()\n",
    "users['age'] = age_scaler.fit_transform(users[['age']])\n",
    "\n",
    "# Encode occupation\n",
    "occupation_enc = LabelEncoder()\n",
    "users['occupation'] = occupation_enc.fit_transform(users['occupation'])\n",
    "\n",
    "# Process movie data\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "all_genres = sorted(set(g for genres in movies['genres'] for g in genres))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(movies['genres'])\n",
    "\n",
    "genre_df = pd.DataFrame(genre_matrix, columns=mlb.classes_)\n",
    "movies = movies.join(genre_df)\n",
    "\n",
    "# Parse release year\n",
    "movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)').astype(int)\n",
    "\n",
    "# Shift movie_id to start from 1 and handle unknown movies\n",
    "movie_enc = LabelEncoder()\n",
    "movies['movie_id'] = movie_enc.fit_transform(movies['movie_id']) + 1\n",
    "\n",
    "# Merge datasets\n",
    "data = pd.merge(ratings, users, on='user_id', how='left')\n",
    "data = pd.merge(data, movies, on='movie_id', how='left')\n",
    "\n",
    "# Select relevant columns\n",
    "user_features = ['gender', 'age', 'occupation']\n",
    "movie_features = list(mlb.classes_) + ['year']\n",
    "data = data[['user_id', 'movie_id', 'rating'] + user_features + movie_features + ['timestamp']]\n",
    "\n",
    "\n",
    "# Temporal split (80/20)\n",
    "train_size = int(0.8 * len(data))\n",
    "\n",
    "data['year'] = data['year'].fillna(-1)\n",
    "data[list(mlb.classes_)] = data[list(mlb.classes_)].fillna(-1)\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]\n",
    "\n",
    "n_users = train_data['user_id'].nunique()\n",
    "n_movies = train_data['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id        0\n",
       "movie_id       0\n",
       "rating         0\n",
       "gender         0\n",
       "age            0\n",
       "occupation     0\n",
       "Action         0\n",
       "Adventure      0\n",
       "Animation      0\n",
       "Children's     0\n",
       "Comedy         0\n",
       "Crime          0\n",
       "Documentary    0\n",
       "Drama          0\n",
       "Fantasy        0\n",
       "Film-Noir      0\n",
       "Horror         0\n",
       "Musical        0\n",
       "Mystery        0\n",
       "Romance        0\n",
       "Sci-Fi         0\n",
       "Thriller       0\n",
       "War            0\n",
       "Western        0\n",
       "year           0\n",
       "timestamp      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['gender', 'age', 'occupation']\n",
    "movie_features = all_genres + ['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ids = set(train_data['user_id'].values.tolist())\n",
    "train_movie_ids = set(train_data['movie_id'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, data,user_features,movie_features,user_embedding_id_mapper, movie_embedding_id_mapper):\n",
    "        self.data = data\n",
    "        self.user_features = user_features\n",
    "        self.movie_features = movie_features\n",
    "        self.user_embedding_id_mapper = user_embedding_id_mapper\n",
    "        self.movie_embedding_id_mapper = movie_embedding_id_mapper\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        user_id = torch.tensor(self.user_embedding_id_mapper.get(row['user_id'],0), dtype=torch.long)\n",
    "        movie_id = torch.tensor(self.movie_embedding_id_mapper.get(row['movie_id'],0), dtype=torch.long)\n",
    "        rating = row['rating']\n",
    "        user_features_tensor = torch.tensor(row[self.user_features].values, dtype=torch.float32)\n",
    "        movie_features_tensor = torch.tensor(row[self.movie_features].values, dtype=torch.float32)\n",
    "        return user_id, user_features_tensor, movie_id, movie_features_tensor, rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding_id_mapper = {user_id: idx for idx, user_id in enumerate(train_user_ids,start=1)}\n",
    "movie_embedding_id_mapper = {movie_id: idx for idx, movie_id in enumerate(train_movie_ids,start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "# Prepare training and validation datasets\n",
    "train_dataset = MovieLensDataset(train_data,user_features, movie_features,user_embedding_id_mapper,movie_embedding_id_mapper)\n",
    "val_dataset = MovieLensDataset(val_data,user_features,movie_features,user_embedding_id_mapper,movie_embedding_id_mapper)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8,prefetch_factor=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4,prefetch_factor=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 5.2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m val_pbar \u001b[38;5;241m=\u001b[39m tqdm(val_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_pbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Move data to the appropriate device\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/multiprocessing/connection.py:1136\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/run/media/nazara/ec26c78b-20bc-47f1-b2d5-33a92d92c9b6/conda/envs/recsys_ucu/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "\n",
    "# Define the model parameters\n",
    "n_dim = 50\n",
    "n_user_features = len(user_features)\n",
    "n_movie_features = len(movie_features)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_users = len(train_user_ids) + 1\n",
    "n_movies = len(train_movie_ids) + 1\n",
    "model = RecommenderV3(n_users, n_movies, n_dim, n_user_features, n_movie_features).to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    train_pbar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}/{n_epochs}\", leave=False)\n",
    "    for user_id, user_features, movie_id, movie_features, rating in train_pbar:\n",
    "        # Move data to the appropriate device\n",
    "        user_id = user_id.to(device).long()\n",
    "        user_features = user_features.to(device)\n",
    "        movie_id = movie_id.to(device).long()\n",
    "        movie_features = movie_features.to(device)\n",
    "        rating = rating.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(user_id, user_features, movie_id, movie_features)\n",
    "        loss = criterion(outputs.squeeze(), rating)\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * user_id.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Training Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_pbar = tqdm(val_dataloader, desc=f\"Validation Epoch {epoch+1}/{n_epochs}\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for user_id, user_features, movie_id, movie_features, rating in val_pbar:\n",
    "            # Move data to the appropriate device\n",
    "            user_id = user_id.to(device).long()\n",
    "            user_features = user_features.to(device)\n",
    "            movie_id = movie_id.to(device).long()\n",
    "            movie_features = movie_features.to(device)\n",
    "            rating = rating.to(device).float()\n",
    "            \n",
    "            outputs = model(user_id, user_features, movie_id, movie_features)\n",
    "            loss = criterion(outputs.squeeze(), rating)\n",
    "            val_loss += loss.item() * user_id.size(0)\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_checkpoint(model, optimizer, epoch, loss, genre_enc, user_enc, movie_enc, file_path='checkpoint.pth'):\n",
    "#     state = {\n",
    "#         'epoch': epoch,\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#         'loss': loss,\n",
    "#         'genre_enc': genre_enc,\n",
    "#         'user_enc': user_enc,\n",
    "#         'movie_enc': movie_enc\n",
    "#     }\n",
    "#     torch.save(state, file_path)\n",
    "#     print(f'Checkpoint saved at {file_path}')\n",
    "\n",
    "# import os \n",
    "# os.makedirs('../../artifacts/dl_model', exist_ok=True)\n",
    "# save_checkpoint(model, optimizer, n_epochs, val_loss, mlb, user_enc, movie_enc, '../../artifacts/dl_model/recommeder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(file_path, model, optimizer):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    genre_enc = checkpoint['genre_enc']\n",
    "    user_enc = checkpoint['user_enc']\n",
    "    movie_enc = checkpoint['movie_enc']\n",
    "    print(f'Checkpoint loaded: Epoch {epoch}, Loss: {loss:.4f}')\n",
    "    return epoch, loss, genre_enc, user_enc, movie_enc\n",
    "\n",
    "# Example usage\n",
    "n_users = data['user_id'].nunique()\n",
    "n_movies = data['movie_id'].nunique()\n",
    "n_dim = 50\n",
    "n_user_features = len(user_features)\n",
    "n_movie_features = len(movie_features)\n",
    "\n",
    "model2 = RecommenderV3(n_users, n_movies, n_dim, n_user_features, n_movie_features).cuda()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.0001)\n",
    "start_epoch, start_loss, genre_enc, user_enc, movie_enc = load_checkpoint('../../artifacts/dl_model/recommeder.pth', model2, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1369.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46 261  91 271  56  88 144 117 325 270 377 255 256  25 405 484  18  16\n",
      " 162 159 147  27 423 446 341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_recommendations(model, user_id_tensor, user_features_tensor, movie_ids_tensor, movie_features_tensor, top_k=25, batch_size=512):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Make batched predictions\n",
    "        predictions = []\n",
    "        for i in tqdm(range(0, len(movie_ids_tensor), batch_size)):\n",
    "            batch_user_id = user_id_tensor[i:i+batch_size]\n",
    "            batch_user_features = user_features_tensor[i:i+batch_size]\n",
    "            batch_movie_ids = movie_ids_tensor[i:i+batch_size]\n",
    "            batch_movie_features = movie_features_tensor[i:i+batch_size]\n",
    "            \n",
    "            batch_predictions = model(batch_user_id, batch_user_features, batch_movie_ids, batch_movie_features)\n",
    "            predictions.append(batch_predictions.cpu().numpy())\n",
    "        \n",
    "        # Concatenate predictions from batches\n",
    "        predictions = np.concatenate(predictions)\n",
    "    \n",
    "    predictions = predictions.squeeze()\n",
    "    # Get top-k movie indices\n",
    "    top_k_indices = predictions.argsort()[-top_k:][::-1]\n",
    "    print(top_k_indices)\n",
    "    recommended_movie_ids = movie_ids_tensor[top_k_indices.copy()].cpu().numpy()\n",
    "    return recommended_movie_ids.tolist()\n",
    "\n",
    "# Example user selection\n",
    "user_id = val_data['user_id'].iloc[0]\n",
    "user_row = val_data[val_data['user_id'] == user_id].iloc[0]\n",
    "user_features = [\n",
    "    user_row['age'],\n",
    "    user_row['gender'],\n",
    "    user_row['occupation']\n",
    "]\n",
    "\n",
    "# Example: Assume movies_user_didnt_see is already defined\n",
    "movies_user_didnt_see = val_data['movie_id'].unique()  # Replace with actual list of unseen movies\n",
    "\n",
    "# Prepare movie features for all movies the user didn't see\n",
    "movie_ids = movies_user_didnt_see\n",
    "movie_features = []\n",
    "for movie_id in movie_ids:\n",
    "    movie_row = val_data[val_data['movie_id'] == movie_id].iloc[0]\n",
    "    movie_feature = np.concatenate([\n",
    "        movie_row[all_genres].values,\n",
    "        np.array([movie_row['year']])\n",
    "    ])\n",
    "    movie_features.append(movie_feature)\n",
    "\n",
    "movie_ids = [movie_embedding_id_mapper.get(movie_id,0) for movie_id in movie_ids]\n",
    "# Convert user_id, user_features, movie_ids, and movie_features to tensors\n",
    "user_id_tensor = torch.tensor([user_embedding_id_mapper.get(user_id,0)] * len(movie_ids), dtype=torch.long).cuda()[:512]\n",
    "user_features_tensor = torch.tensor([user_features] * len(movie_ids), dtype=torch.float).cuda()[:512]\n",
    "movie_ids_tensor = torch.tensor(movie_ids, dtype=torch.long).cuda()[:512]\n",
    "movie_features_tensor = torch.tensor(movie_features, dtype=torch.float).cuda()[:512]\n",
    "\n",
    "# Generate recommendations for the user\n",
    "recommended_movie_ids = get_recommendations(model, user_id_tensor, user_features_tensor, movie_ids_tensor, movie_features_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2(user_id_tensor, user_features_tensor, movie_ids_tensor, movie_features_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_id_tensor.dtype)\n",
    "print(user_features_tensor.dtype)\n",
    "print(movie_ids_tensor.dtype)\n",
    "print(movie_features_tensor.dtype)\n",
    "\n",
    "#print shapes\n",
    "print(user_id_tensor.shape)\n",
    "print(user_features_tensor.shape)\n",
    "print(movie_ids_tensor.shape)\n",
    "print(movie_features_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, movie_ids_tensor, _, _ = next(train_dataloader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(user_id_tensor.dtype)\n",
    "# print(user_features_tensor.dtype)\n",
    "# print(movie_ids_tensor.dtype)\n",
    "# print(movie_features_tensor.dtype)\n",
    "\n",
    "# #print shapes\n",
    "# print(user_id_tensor.shape)\n",
    "# print(user_features_tensor.shape)\n",
    "# print(movie_ids_tensor.shape)\n",
    "# print(movie_features_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7674],\n",
       "        [2.8272],\n",
       "        [2.8457],\n",
       "        [2.8328],\n",
       "        [2.8027],\n",
       "        [2.8331],\n",
       "        [2.8339],\n",
       "        [2.8280],\n",
       "        [2.8441],\n",
       "        [2.8023],\n",
       "        [2.8098],\n",
       "        [2.8278],\n",
       "        [2.8179],\n",
       "        [2.8172],\n",
       "        [2.8323],\n",
       "        [2.8342],\n",
       "        [2.8493],\n",
       "        [2.8393],\n",
       "        [2.8494],\n",
       "        [2.8167],\n",
       "        [2.8290],\n",
       "        [2.8273],\n",
       "        [2.7944],\n",
       "        [2.8227],\n",
       "        [2.8339],\n",
       "        [2.8506],\n",
       "        [2.8047],\n",
       "        [2.8480],\n",
       "        [2.7802],\n",
       "        [2.7517],\n",
       "        [2.8313],\n",
       "        [2.8222],\n",
       "        [2.8376],\n",
       "        [2.7960],\n",
       "        [2.7851],\n",
       "        [2.8445],\n",
       "        [2.8411],\n",
       "        [2.8305],\n",
       "        [2.8329],\n",
       "        [2.8277],\n",
       "        [2.8459],\n",
       "        [2.8456],\n",
       "        [2.8206],\n",
       "        [2.8196],\n",
       "        [2.8216],\n",
       "        [2.8169],\n",
       "        [2.8693],\n",
       "        [2.8080],\n",
       "        [2.7707],\n",
       "        [2.8206],\n",
       "        [2.8422],\n",
       "        [2.8380],\n",
       "        [2.7848],\n",
       "        [2.7893],\n",
       "        [2.8185],\n",
       "        [2.7627],\n",
       "        [2.8594],\n",
       "        [2.8239],\n",
       "        [2.8073],\n",
       "        [2.8320],\n",
       "        [2.8445],\n",
       "        [2.8175],\n",
       "        [2.7815],\n",
       "        [2.8075],\n",
       "        [2.7708],\n",
       "        [2.7524],\n",
       "        [2.7745],\n",
       "        [2.8249],\n",
       "        [2.7717],\n",
       "        [2.7942],\n",
       "        [2.8384],\n",
       "        [2.8285],\n",
       "        [2.8271],\n",
       "        [2.7348],\n",
       "        [2.8021],\n",
       "        [2.8395],\n",
       "        [2.7339],\n",
       "        [2.7781],\n",
       "        [2.7430],\n",
       "        [2.7586],\n",
       "        [2.7766],\n",
       "        [2.8388],\n",
       "        [2.8191],\n",
       "        [2.8075],\n",
       "        [2.7914],\n",
       "        [2.8147],\n",
       "        [2.8399],\n",
       "        [2.8371],\n",
       "        [2.8547],\n",
       "        [2.8373],\n",
       "        [2.8290],\n",
       "        [2.8631],\n",
       "        [2.8321],\n",
       "        [2.8133],\n",
       "        [2.8231],\n",
       "        [2.8097],\n",
       "        [2.8189],\n",
       "        [2.8259],\n",
       "        [2.8286],\n",
       "        [2.7898],\n",
       "        [2.8384],\n",
       "        [2.7964],\n",
       "        [2.7971],\n",
       "        [2.8316],\n",
       "        [2.8423],\n",
       "        [2.8253],\n",
       "        [2.8355],\n",
       "        [2.8175],\n",
       "        [2.8383],\n",
       "        [2.7589],\n",
       "        [2.8232],\n",
       "        [2.8410],\n",
       "        [2.7818],\n",
       "        [2.8272],\n",
       "        [2.8415],\n",
       "        [2.8453],\n",
       "        [2.8401],\n",
       "        [2.8529],\n",
       "        [2.7700],\n",
       "        [2.8250],\n",
       "        [2.8196],\n",
       "        [2.7953],\n",
       "        [2.8194],\n",
       "        [2.8301],\n",
       "        [2.8196],\n",
       "        [2.8200],\n",
       "        [2.7795],\n",
       "        [2.7359],\n",
       "        [2.7422],\n",
       "        [2.7879],\n",
       "        [2.8188],\n",
       "        [2.8113],\n",
       "        [2.8069],\n",
       "        [2.8330],\n",
       "        [2.7465],\n",
       "        [2.7515],\n",
       "        [2.7381],\n",
       "        [2.7071],\n",
       "        [2.7239],\n",
       "        [2.7944],\n",
       "        [2.8315],\n",
       "        [2.7456],\n",
       "        [2.8225],\n",
       "        [2.8262],\n",
       "        [2.8547],\n",
       "        [2.8255],\n",
       "        [2.8044],\n",
       "        [2.8480],\n",
       "        [2.8406],\n",
       "        [2.8118],\n",
       "        [2.8280],\n",
       "        [2.8434],\n",
       "        [2.8447],\n",
       "        [2.7312],\n",
       "        [2.8377],\n",
       "        [2.8344],\n",
       "        [2.8161],\n",
       "        [2.8041],\n",
       "        [2.8318],\n",
       "        [2.8482],\n",
       "        [2.8278],\n",
       "        [2.8207],\n",
       "        [2.8493],\n",
       "        [2.8413],\n",
       "        [2.8234],\n",
       "        [2.8177],\n",
       "        [2.8170],\n",
       "        [2.8107],\n",
       "        [2.8206],\n",
       "        [2.8311],\n",
       "        [2.8418],\n",
       "        [2.8436],\n",
       "        [2.8328],\n",
       "        [2.7877],\n",
       "        [2.8246],\n",
       "        [2.8116],\n",
       "        [2.8216],\n",
       "        [2.7946],\n",
       "        [2.8268],\n",
       "        [2.8253],\n",
       "        [2.7811],\n",
       "        [2.8186],\n",
       "        [2.8306],\n",
       "        [2.8370],\n",
       "        [2.8223],\n",
       "        [2.8382],\n",
       "        [2.8073],\n",
       "        [2.8137],\n",
       "        [2.8462],\n",
       "        [2.8432],\n",
       "        [2.8363],\n",
       "        [2.8386],\n",
       "        [2.8436],\n",
       "        [2.8283],\n",
       "        [2.8423],\n",
       "        [2.8377],\n",
       "        [2.8217],\n",
       "        [2.8342],\n",
       "        [2.8290],\n",
       "        [2.8100],\n",
       "        [2.8405],\n",
       "        [2.8289],\n",
       "        [2.8164],\n",
       "        [2.8302],\n",
       "        [2.8146],\n",
       "        [2.8303],\n",
       "        [2.8393],\n",
       "        [2.8440],\n",
       "        [2.8420],\n",
       "        [2.7880],\n",
       "        [2.8153],\n",
       "        [2.8171],\n",
       "        [2.8167],\n",
       "        [2.8058],\n",
       "        [2.8249],\n",
       "        [2.8235],\n",
       "        [2.8046],\n",
       "        [2.8231],\n",
       "        [2.8302],\n",
       "        [2.7695],\n",
       "        [2.7626],\n",
       "        [2.8218],\n",
       "        [2.8127],\n",
       "        [2.8002],\n",
       "        [2.8385],\n",
       "        [2.8314],\n",
       "        [2.8200],\n",
       "        [2.7912],\n",
       "        [2.8342],\n",
       "        [2.8158],\n",
       "        [2.8340],\n",
       "        [2.8352],\n",
       "        [2.7759],\n",
       "        [2.8445],\n",
       "        [2.8106],\n",
       "        [2.8242],\n",
       "        [2.7744],\n",
       "        [2.8194],\n",
       "        [2.8283],\n",
       "        [2.8109],\n",
       "        [2.8386],\n",
       "        [2.8128],\n",
       "        [2.7923],\n",
       "        [2.8388],\n",
       "        [2.8275],\n",
       "        [2.7922],\n",
       "        [2.8365],\n",
       "        [2.8361],\n",
       "        [2.8249],\n",
       "        [2.8414],\n",
       "        [2.8348],\n",
       "        [2.8441],\n",
       "        [2.8381],\n",
       "        [2.8301],\n",
       "        [2.8447],\n",
       "        [2.8508],\n",
       "        [2.8507],\n",
       "        [2.8245],\n",
       "        [2.8054],\n",
       "        [2.8322],\n",
       "        [2.7798],\n",
       "        [2.8641],\n",
       "        [2.8266],\n",
       "        [2.8146],\n",
       "        [2.8330],\n",
       "        [2.8221],\n",
       "        [2.8398],\n",
       "        [2.8312],\n",
       "        [2.8390],\n",
       "        [2.8289],\n",
       "        [2.8513],\n",
       "        [2.8608],\n",
       "        [2.8423],\n",
       "        [2.8122],\n",
       "        [2.8427],\n",
       "        [2.8171],\n",
       "        [2.8244],\n",
       "        [2.8126],\n",
       "        [2.8315],\n",
       "        [2.8378],\n",
       "        [2.8262],\n",
       "        [2.8292],\n",
       "        [2.8256],\n",
       "        [2.8235],\n",
       "        [2.8340],\n",
       "        [2.8100],\n",
       "        [2.8233],\n",
       "        [2.8200],\n",
       "        [2.8447],\n",
       "        [2.8352],\n",
       "        [2.8353],\n",
       "        [2.8372],\n",
       "        [2.8159],\n",
       "        [2.8249],\n",
       "        [2.8108],\n",
       "        [2.8343],\n",
       "        [2.8417],\n",
       "        [2.8359],\n",
       "        [2.8237],\n",
       "        [2.8314],\n",
       "        [2.8217],\n",
       "        [2.8380],\n",
       "        [2.8155],\n",
       "        [2.8179],\n",
       "        [2.8137],\n",
       "        [2.8325],\n",
       "        [2.8143],\n",
       "        [2.7672],\n",
       "        [2.8406],\n",
       "        [2.8324],\n",
       "        [2.7607],\n",
       "        [2.7467],\n",
       "        [2.7612],\n",
       "        [2.8324],\n",
       "        [2.8387],\n",
       "        [2.8300],\n",
       "        [2.8201],\n",
       "        [2.8358],\n",
       "        [2.8285],\n",
       "        [2.8382],\n",
       "        [2.8160],\n",
       "        [2.8417],\n",
       "        [2.8238],\n",
       "        [2.8301],\n",
       "        [2.8331],\n",
       "        [2.8528],\n",
       "        [2.8338],\n",
       "        [2.8460],\n",
       "        [2.8277],\n",
       "        [2.8325],\n",
       "        [2.8263],\n",
       "        [2.8017],\n",
       "        [2.8366],\n",
       "        [2.7971],\n",
       "        [2.7938],\n",
       "        [2.7687],\n",
       "        [2.8255],\n",
       "        [2.8018],\n",
       "        [2.7933],\n",
       "        [2.7962],\n",
       "        [2.8376],\n",
       "        [2.8470],\n",
       "        [2.8267],\n",
       "        [2.8377],\n",
       "        [2.8201],\n",
       "        [2.8177],\n",
       "        [2.8366],\n",
       "        [2.8213],\n",
       "        [2.8400],\n",
       "        [2.8330],\n",
       "        [2.7981],\n",
       "        [2.8021],\n",
       "        [2.8266],\n",
       "        [2.7816],\n",
       "        [2.8285],\n",
       "        [2.7668],\n",
       "        [2.8179],\n",
       "        [2.8251],\n",
       "        [2.8355],\n",
       "        [2.7851],\n",
       "        [2.8358],\n",
       "        [2.8188],\n",
       "        [2.8256],\n",
       "        [2.8225],\n",
       "        [2.7631],\n",
       "        [2.8329],\n",
       "        [2.8145],\n",
       "        [2.8416],\n",
       "        [2.8225],\n",
       "        [2.8443],\n",
       "        [2.8377],\n",
       "        [2.8140],\n",
       "        [2.8127],\n",
       "        [2.8402],\n",
       "        [2.8254],\n",
       "        [2.8227],\n",
       "        [2.8249],\n",
       "        [2.8511],\n",
       "        [2.8185],\n",
       "        [2.8275],\n",
       "        [2.7911],\n",
       "        [2.7743],\n",
       "        [2.8388],\n",
       "        [2.8328],\n",
       "        [2.8420],\n",
       "        [2.8314],\n",
       "        [2.8325],\n",
       "        [2.8305],\n",
       "        [2.8236],\n",
       "        [2.8024],\n",
       "        [2.8058],\n",
       "        [2.8217],\n",
       "        [2.8461],\n",
       "        [2.8293],\n",
       "        [2.8384],\n",
       "        [2.8185],\n",
       "        [2.8326],\n",
       "        [2.8207],\n",
       "        [2.8143],\n",
       "        [2.8347],\n",
       "        [2.7897],\n",
       "        [2.8228],\n",
       "        [2.7695],\n",
       "        [2.7961],\n",
       "        [2.8199],\n",
       "        [2.8499],\n",
       "        [2.7643],\n",
       "        [2.8342],\n",
       "        [2.8343],\n",
       "        [2.7959],\n",
       "        [2.8236],\n",
       "        [2.8128],\n",
       "        [2.8428],\n",
       "        [2.7700],\n",
       "        [2.8247],\n",
       "        [2.8013],\n",
       "        [2.8310],\n",
       "        [2.8279],\n",
       "        [2.7580],\n",
       "        [2.8418],\n",
       "        [2.8090],\n",
       "        [2.8447],\n",
       "        [2.8442],\n",
       "        [2.8477],\n",
       "        [2.8461],\n",
       "        [2.8237],\n",
       "        [2.8430],\n",
       "        [2.7758],\n",
       "        [2.8308],\n",
       "        [2.8290],\n",
       "        [2.7729],\n",
       "        [2.8146],\n",
       "        [2.8012],\n",
       "        [2.8233],\n",
       "        [2.8012],\n",
       "        [2.8188],\n",
       "        [2.8367],\n",
       "        [2.8378],\n",
       "        [2.8162],\n",
       "        [2.7979],\n",
       "        [2.8279],\n",
       "        [2.8274],\n",
       "        [2.8273],\n",
       "        [2.8388],\n",
       "        [2.8391],\n",
       "        [2.8222],\n",
       "        [2.8471],\n",
       "        [2.8218],\n",
       "        [2.8270],\n",
       "        [2.7605],\n",
       "        [2.8114],\n",
       "        [2.8297],\n",
       "        [2.8204],\n",
       "        [2.8253],\n",
       "        [2.8143],\n",
       "        [2.8175],\n",
       "        [2.8089],\n",
       "        [2.8242],\n",
       "        [2.8119],\n",
       "        [2.8270],\n",
       "        [2.8310],\n",
       "        [2.8302],\n",
       "        [2.8293],\n",
       "        [2.7855],\n",
       "        [2.8196],\n",
       "        [2.8380],\n",
       "        [2.8384],\n",
       "        [2.7366],\n",
       "        [2.7654],\n",
       "        [2.7971],\n",
       "        [2.7391],\n",
       "        [2.8155],\n",
       "        [2.8179],\n",
       "        [2.8343],\n",
       "        [2.8410],\n",
       "        [2.7794],\n",
       "        [2.8143],\n",
       "        [2.8353],\n",
       "        [2.8350],\n",
       "        [2.8360],\n",
       "        [2.8029],\n",
       "        [2.8361],\n",
       "        [2.8109],\n",
       "        [2.8346],\n",
       "        [2.8496],\n",
       "        [2.7923],\n",
       "        [2.8417],\n",
       "        [2.7662],\n",
       "        [2.8364],\n",
       "        [2.7939],\n",
       "        [2.8404],\n",
       "        [2.8290],\n",
       "        [2.7978],\n",
       "        [2.8255],\n",
       "        [2.7775],\n",
       "        [2.8317],\n",
       "        [2.8091],\n",
       "        [2.8235],\n",
       "        [2.8291],\n",
       "        [2.8361],\n",
       "        [2.8309],\n",
       "        [2.8300],\n",
       "        [2.8179],\n",
       "        [2.8321],\n",
       "        [2.8443],\n",
       "        [2.8046],\n",
       "        [2.8124],\n",
       "        [2.8092],\n",
       "        [2.7619],\n",
       "        [2.8325],\n",
       "        [2.7917],\n",
       "        [2.8298]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(user_id_tensor.cuda(), user_features_tensor.cuda(), movie_ids_tensor.cuda(), movie_features_tensor.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_ucu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
