{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:21:23.165636Z",
     "start_time": "2024-08-11T15:21:23.142098Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "# add root folder to path\n",
    "folder = \"../../\"\n",
    "sys.path.append(folder)\n",
    "from src.utils import load_data\n",
    "from src.metrics import evaluate_recommender_system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30cc0c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m814.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ec346fab2ff457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:21:30.382561Z",
     "start_time": "2024-08-11T15:21:23.147813Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10779/3481489820.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['year'].fillna(data['year'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "users, ratings, movies = load_data('../../data/ml-1m')\n",
    "\n",
    "# Merge datasets\n",
    "data = ratings.merge(users, on='user_id').merge(movies, on='movie_id')\n",
    "data['year'] = data['title'].str.extract(r'\\((\\d{4})\\)').astype(float)\n",
    "data['genres'] = data['genres'].str.split('|')\n",
    "genre_columns = pd.get_dummies(data['genres'].explode()).groupby(level=0).max()\n",
    "data = data.join(genre_columns).drop(columns=['title', 'genres', 'zip'])\n",
    "data['year'].fillna(data['year'].median(), inplace=True)\n",
    "data['gender'] = data['gender'].apply(lambda x: x == 'M')\n",
    "data.drop(columns=['timestamp'], inplace=True)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data.head()\n",
    "\n",
    "movie_features_names = ['year', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
    "                        'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
    "                        'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6452a5ce0aaac4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:22:47.519953Z",
     "start_time": "2024-08-11T15:21:30.384603Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "surprise_data = Dataset.load_from_df(train_data[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset = surprise_data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "def generate_candidates(algo, test_data, num_candidates=25):\n",
    "    user_ids = test_data['user_id'].unique()\n",
    "    candidates = {}\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        all_movie_ids = test_data['movie_id'].unique()\n",
    "\n",
    "        rated_movie_ids = train_data[train_data['user_id'] == user_id]['movie_id'].unique()\n",
    "\n",
    "        # Predict ratings for movies the user hasn't rated\n",
    "        unseen_movie_ids = list(set(all_movie_ids) - set(rated_movie_ids))\n",
    "        predictions = [(movie_id, algo.predict(user_id, movie_id).est) for movie_id in unseen_movie_ids]\n",
    "\n",
    "        top_candidates = sorted(predictions, key=lambda x: x[1], reverse=True)[:num_candidates]\n",
    "        candidates[user_id] = [movie_id for movie_id, _ in top_candidates]\n",
    "\n",
    "    return candidates\n",
    "\n",
    "# Generate candidates\n",
    "candidates = generate_candidates(algo, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18fce25356ab296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:22:47.525341Z",
     "start_time": "2024-08-11T15:22:47.519049Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rank_recommendations(model, test_data, recommendations, device='cpu'):\n",
    "    model.eval()\n",
    "    ranked_recommendations = {}\n",
    "\n",
    "    for user_id, movie_ids in recommendations.items():\n",
    "        user_features = test_data[test_data['user_id'] == user_id][['gender', 'age', 'occupation']].iloc[0].values\n",
    "        movie_features = []\n",
    "        for movie_id in movie_ids:\n",
    "            movie_features.append(test_data[test_data['movie_id'] == movie_id][movie_features_names].iloc[0].values)\n",
    "\n",
    "        user_features = np.array(user_features)\n",
    "        movie_features = np.array(movie_features)\n",
    "\n",
    "        num_movies = len(movie_ids)\n",
    "        num_features_per_movie = len(movie_features_names)\n",
    "\n",
    "        if num_movies < 25:\n",
    "            padding_size = 25 - num_movies\n",
    "            padding_array = -1 * np.ones((padding_size, num_features_per_movie))\n",
    "            movie_features = np.vstack((movie_features, padding_array))\n",
    "\n",
    "        user_features_tensor = torch.tensor(user_features.astype(np.float32), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        movie_features_tensor = torch.tensor(movie_features.astype(np.float32), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        pred_scores = model(user_features_tensor, movie_features_tensor)\n",
    "\n",
    "        pred_scores = pred_scores[:num_movies]\n",
    "        sorted_indices = torch.argsort(pred_scores, descending=True).cpu().numpy()\n",
    "        ranked_recommendations[user_id] = [movie_ids[i] for i in sorted_indices]\n",
    "\n",
    "    return ranked_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfe5e181d28ccfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:22:47.533176Z",
     "start_time": "2024-08-11T15:22:47.528544Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ListwiseRankingModel(nn.Module):\n",
    "    def __init__(self, user_feature_dim, movie_feature_dim, hidden_dim=64):\n",
    "        super(ListwiseRankingModel, self).__init__()\n",
    "        self.user_feature_layer = nn.Linear(user_feature_dim, hidden_dim)\n",
    "        self.movie_feature_layer = nn.Linear(movie_feature_dim, hidden_dim)\n",
    "        self.merging_layer = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user_features, movie_features):\n",
    "        # Process user features\n",
    "        user_hidden = F.relu(self.user_feature_layer(user_features))\n",
    "\n",
    "        # Process movie features\n",
    "        movie_hidden = F.relu(self.movie_feature_layer(movie_features))\n",
    "\n",
    "        # Merge user and movie features\n",
    "        merged_features = torch.cat((user_hidden.unsqueeze(1).repeat(1, movie_features.size(1), 1), movie_hidden), dim=2)\n",
    "        merged_hidden = F.relu(self.merging_layer(merged_features))\n",
    "\n",
    "        # Compute scores for each movie\n",
    "        scores = self.output_layer(merged_hidden)\n",
    "        return scores.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80321c464fa452c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:23:39.376465Z",
     "start_time": "2024-08-11T15:22:47.534299Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_feature_dim = len(['gender', 'age', 'occupation'])\n",
    "movie_feature_dim = len(movie_features_names)\n",
    "model = ListwiseRankingModel(user_feature_dim, movie_feature_dim)\n",
    "model.load_state_dict(torch.load('../../artifacts/listwise_ranking_model.pth', map_location=torch.device('cpu'), weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "ranked_recommendations = rank_recommendations(model, test_data, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f20fd5f13d61ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T15:23:50.534792Z",
     "start_time": "2024-08-11T15:23:39.378601Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Evaluation: {'Precision@K': 0.06525339516396157, 'Recall@K': 0.05368786126232795, 'NDCG@K': 0.46282655775759757, 'MAP@K': 0.28174415732139624, 'MRR': 0.21603074074903086, 'Hit Rate@K': 0.5889367340178867, 'Coverage@K': 0.3330429732868757}\n",
      "Ranked Evaluation: {'Precision@K': 0.06525339516396157, 'Recall@K': 0.05368786126232795, 'NDCG@K': 0.4179895101246726, 'MAP@K': 0.1964962913356608, 'MRR': 0.1476819917805729, 'Hit Rate@K': 0.5889367340178867, 'Coverage@K': 0.3330429732868757}\n"
     ]
    }
   ],
   "source": [
    "total_amount_of_movies = test_data['movie_id'].nunique()\n",
    "initial_evaluation = evaluate_recommender_system(candidates, test_data, total_amount_of_movies,k=25)\n",
    "ranked_evaluation = evaluate_recommender_system(ranked_recommendations, test_data, total_amount_of_movies,k=25)\n",
    "\n",
    "print(\"Initial Evaluation:\", initial_evaluation)\n",
    "print(\"Ranked Evaluation:\", ranked_evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcdcc5639e1b7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see:\n",
    " -> NDCG,. MAP AND MRR got worse after ranking, showing the model isn't helping much.\n",
    " -> More diverse items were recommended, but it hurt precision and recall.\n",
    " -> The model and features need better tuning; that's why we don't see big benefits.\n",
    " \n",
    "Overall, the ranking didn't add much value because the model needs more further tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc36938ff601d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Drawbacks and benefits of 2-stage RS\n",
    "\n",
    "### Drawbacks:\n",
    "1. **More Complex**: A two-stage system is harder to set up and maintain.\n",
    "2. **Higher Costs**: Running two steps uses more computing power.\n",
    "3. **Risk of Worse Results**: If not tuned well, the ranking step can lower recommendation quality(actually what we can see on practice).\n",
    "4. **Slower Fixes**: Problems can take longer to fix because of the extra step.\n",
    "\n",
    "### Benefits:\n",
    "1. **Better Accuracy**: When done right, this approach can give more personalized recommendations.\n",
    "2. **Scalable**: It can handle large datasets better by narrowing down options first.\n",
    "3. **Flexible**: You can use different models for each step, making it easier to improve.\n",
    "4. **Improved User Experience**: Helps deliver more relevant recommendations to users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
