{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:02:58.746355Z",
     "start_time": "2024-08-17T17:02:58.733524Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "# add root folder to path\n",
    "folder = \"../../\"\n",
    "sys.path.append(folder)\n",
    "from src.utils import load_data\n",
    "from src.metrics import evaluate_recommender_system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "30cc0c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T17:02:59.746247Z",
     "start_time": "2024-08-17T17:02:58.742319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0.0 in /Users/pavlo.borysenko/final/lib/python3.9/site-packages (1.26.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "29ec346fab2ff457",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:03:07.058256Z",
     "start_time": "2024-08-17T17:02:59.751586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "users, ratings, movies = load_data('../../data/ml-1m')\n",
    "\n",
    "# Merge datasets\n",
    "data = ratings.merge(users, on='user_id').merge(movies, on='movie_id')\n",
    "data['year'] = data['title'].str.extract(r'\\((\\d{4})\\)').astype(float)\n",
    "data['genres'] = data['genres'].str.split('|')\n",
    "genre_columns = pd.get_dummies(data['genres'].explode()).groupby(level=0).max()\n",
    "data = data.join(genre_columns).drop(columns=['title', 'genres', 'zip'])\n",
    "data['year'].fillna(data['year'].median(), inplace=True)\n",
    "data['gender'] = data['gender'].apply(lambda x: x == 'M')\n",
    "data.drop(columns=['timestamp'], inplace=True)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data.head()\n",
    "\n",
    "movie_features_names = ['year', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
    "                        'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
    "                        'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f6452a5ce0aaac4d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:04:33.166262Z",
     "start_time": "2024-08-17T17:03:07.062028Z"
    }
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "surprise_data = Dataset.load_from_df(train_data[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset = surprise_data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "def generate_candidates(algo, test_data, num_candidates=25):\n",
    "    user_ids = test_data['user_id'].unique()\n",
    "    candidates = {}\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        all_movie_ids = test_data['movie_id'].unique()\n",
    "\n",
    "        rated_movie_ids = train_data[train_data['user_id'] == user_id]['movie_id'].unique()\n",
    "\n",
    "        # Predict ratings for movies the user hasn't rated\n",
    "        unseen_movie_ids = list(set(all_movie_ids) - set(rated_movie_ids))\n",
    "        predictions = [(movie_id, algo.predict(user_id, movie_id).est) for movie_id in unseen_movie_ids]\n",
    "\n",
    "        top_candidates = sorted(predictions, key=lambda x: x[1], reverse=True)[:num_candidates]\n",
    "        candidates[user_id] = [movie_id for movie_id, _ in top_candidates]\n",
    "\n",
    "    return candidates\n",
    "\n",
    "# Generate candidates\n",
    "candidates = generate_candidates(algo, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f18fce25356ab296",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:04:33.172291Z",
     "start_time": "2024-08-17T17:04:33.169415Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_recommendations(model, test_data, recommendations, device='cpu'):\n",
    "    model.eval()\n",
    "    ranked_recommendations = {}\n",
    "\n",
    "    for user_id, movie_ids in recommendations.items():\n",
    "        user_features = test_data[test_data['user_id'] == user_id][['gender', 'age', 'occupation']].iloc[0].values\n",
    "        movie_features = []\n",
    "        for movie_id in movie_ids:\n",
    "            movie_features.append(test_data[test_data['movie_id'] == movie_id][movie_features_names].iloc[0].values)\n",
    "\n",
    "        user_features = np.array(user_features)\n",
    "        movie_features = np.array(movie_features)\n",
    "\n",
    "        num_movies = len(movie_ids)\n",
    "        num_features_per_movie = len(movie_features_names)\n",
    "\n",
    "        if num_movies < 25:\n",
    "            padding_size = 25 - num_movies\n",
    "            padding_array = -1 * np.ones((padding_size, num_features_per_movie))\n",
    "            movie_features = np.vstack((movie_features, padding_array))\n",
    "\n",
    "        user_features_tensor = torch.tensor(user_features.astype(np.float32), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        movie_features_tensor = torch.tensor(movie_features.astype(np.float32), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        pred_scores = model(user_features_tensor, movie_features_tensor)\n",
    "\n",
    "        pred_scores = pred_scores[:num_movies]\n",
    "        sorted_indices = torch.argsort(pred_scores, descending=True).cpu().numpy()\n",
    "        ranked_recommendations[user_id] = [movie_ids[i] for i in sorted_indices]\n",
    "\n",
    "    return ranked_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fdfe5e181d28ccfe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:04:33.179214Z",
     "start_time": "2024-08-17T17:04:33.173905Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ListwiseRankingModel(nn.Module):\n",
    "    def __init__(self, user_feature_dim, movie_feature_dim, hidden_dim=64):\n",
    "        super(ListwiseRankingModel, self).__init__()\n",
    "        self.user_feature_layer = nn.Linear(user_feature_dim, hidden_dim)\n",
    "        self.movie_feature_layer = nn.Linear(movie_feature_dim, hidden_dim)\n",
    "        self.merging_layer = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user_features, movie_features):\n",
    "        # Process user features\n",
    "        user_hidden = F.relu(self.user_feature_layer(user_features))\n",
    "\n",
    "        # Process movie features\n",
    "        movie_hidden = F.relu(self.movie_feature_layer(movie_features))\n",
    "\n",
    "        # Merge user and movie features\n",
    "        merged_features = torch.cat((user_hidden.unsqueeze(1).repeat(1, movie_features.size(1), 1), movie_hidden), dim=2)\n",
    "        merged_hidden = F.relu(self.merging_layer(merged_features))\n",
    "\n",
    "        # Compute scores for each movie\n",
    "        scores = self.output_layer(merged_hidden)\n",
    "        return scores.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a80321c464fa452c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:05:32.531824Z",
     "start_time": "2024-08-17T17:04:33.184404Z"
    }
   },
   "outputs": [],
   "source": [
    "user_feature_dim = len(['gender', 'age', 'occupation'])\n",
    "movie_feature_dim = len(movie_features_names)\n",
    "model = ListwiseRankingModel(user_feature_dim, movie_feature_dim)\n",
    "model.load_state_dict(torch.load('../../artifacts/listwise_ranking_model.pth', map_location=torch.device('cpu'), weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "ranked_recommendations = rank_recommendations(model, test_data, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5f20fd5f13d61ba6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T17:05:44.964738Z",
     "start_time": "2024-08-17T17:05:32.532460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Evaluation: {'Precision@K': 0.06462150074540336, 'Recall@K': 0.05409163576709956, 'NDCG@K': 0.4608418675902086, 'MAP@K': 0.28126692365492995, 'MRR': 0.21187939303057574, 'Hit Rate@K': 0.5880404174258738, 'Coverage@K': 0.3273672055427252}\n",
      "Ranked Evaluation: {'Precision@K': 0.06462150074540336, 'Recall@K': 0.05409163576709956, 'NDCG@K': 0.4330756439296512, 'MAP@K': 0.23502255975695308, 'MRR': 0.1614241451410333, 'Hit Rate@K': 0.5880404174258738, 'Coverage@K': 0.3273672055427252}\n"
     ]
    }
   ],
   "source": [
    "total_amount_of_movies = test_data['movie_id'].nunique()\n",
    "initial_evaluation = evaluate_recommender_system(candidates, test_data, total_amount_of_movies,k=25)\n",
    "ranked_evaluation = evaluate_recommender_system(ranked_recommendations, test_data, total_amount_of_movies,k=25)\n",
    "\n",
    "print(\"Initial Evaluation:\", initial_evaluation)\n",
    "print(\"Ranked Evaluation:\", ranked_evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcdcc5639e1b7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see:\n",
    " -> NDCG,. MAP AND MRR got worse after ranking, showing the model isn't helping much.\n",
    " -> More diverse items were recommended, but it hurt precision and recall.\n",
    " -> The model and features need better tuning; that's why we don't see big benefits.\n",
    " \n",
    "Overall, the ranking didn't add much value because the model needs more further tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc36938ff601d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Drawbacks and benefits of 2-stage RS\n",
    "\n",
    "### Drawbacks:\n",
    "1. **More Complex**: A two-stage system is harder to set up and maintain.\n",
    "2. **Higher Costs**: Running two steps uses more computing power.\n",
    "3. **Risk of Worse Results**: If not tuned well, the ranking step can lower recommendation quality(actually what we can see on practice).\n",
    "4. **Slower Fixes**: Problems can take longer to fix because of the extra step.\n",
    "\n",
    "### Benefits:\n",
    "1. **Better Accuracy**: When done right, this approach can give more personalized recommendations.\n",
    "2. **Scalable**: It can handle large datasets better by narrowing down options first.\n",
    "3. **Flexible**: You can use different models for each step, making it easier to improve.\n",
    "4. **Improved User Experience**: Helps deliver more relevant recommendations to users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
